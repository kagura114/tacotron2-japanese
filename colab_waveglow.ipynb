{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 安装依赖\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U tensorflow==1.15.2\n",
    "!pip install -q unidecode tensorboardX\n",
    "!pip install librosa==0.8.0\n",
    "!pip install pysoundfile==0.9.0.post1\n",
    "!pip install unidecode==1.3.4\n",
    "!pip install pyopenjtalk==0.2.0\n",
    "!pip install inflect==5.6.2\n",
    "!pip install janome==0.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 加载Google云端硬盘\n",
    "from google.colab import drive\n",
    "drive.mount('drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@markdown 配置：\n",
    "\n",
    "#@markdown 重新运行即可应用配置的更改\n",
    "\n",
    "#国际 HiFi-GAN 模型(有点机器音): 1qpgI41wNXFcH-iKq1Y42JlBC9j0je8PW\n",
    "#@markdown 你训练好的tacotron2模型的路径填在`Tacotron2_Model`这里\n",
    "Tacotron2_Model = '/content/drive/MyDrive/YOURMODEL'#@param {type:\"string\"}\n",
    "TACOTRON2_ID = Tacotron2_Model\n",
    "HIFIGAN_ID = \"1qpgI41wNXFcH-iKq1Y42JlBC9j0je8PW\"\n",
    "#@markdown 选择预处理文本的cleaner\n",
    "text_cleaner = 'japanese_phrase_cleaners'#@param {type:\"string\"}\n",
    "\n",
    "# Check if Initilized\n",
    "try:\n",
    "    initilized\n",
    "except NameError:\n",
    "    print(\"Setting up, please wait.\\n\")\n",
    "    !pip install tqdm -q\n",
    "    from tqdm.notebook import tqdm\n",
    "    with tqdm(total=5, leave=False) as pbar:\n",
    "        %tensorflow_version 1.x\n",
    "        import os\n",
    "        from os.path import exists, join, basename, splitext\n",
    "        !pip install gdown\n",
    "        git_repo_url = 'https://github.com/CjangCjengh/tacotron2-japanese.git'\n",
    "        project_name = splitext(basename(git_repo_url))[0]\n",
    "        if not exists(project_name):\n",
    "            # clone and install\n",
    "            !git clone -q --recursive {git_repo_url}\n",
    "            !git clone -q --recursive https://github.com/SortAnon/hifi-gan\n",
    "            !pip install -q librosa unidecode\n",
    "        pbar.update(1) # downloaded TT2 and HiFi-GAN\n",
    "        import sys\n",
    "        sys.path.append('hifi-gan')\n",
    "        sys.path.append(project_name)\n",
    "        import time\n",
    "        import matplotlib\n",
    "        import matplotlib.pylab as plt\n",
    "        import gdown\n",
    "        d = 'https://drive.google.com/uc?id='\n",
    "\n",
    "        %matplotlib inline\n",
    "        import IPython.display as ipd\n",
    "        import numpy as np\n",
    "        import torch\n",
    "        import json\n",
    "        from hparams import create_hparams\n",
    "        from model import Tacotron2\n",
    "        from layers import TacotronSTFT\n",
    "        from audio_processing import griffin_lim\n",
    "        from text import text_to_sequence\n",
    "        from env import AttrDict\n",
    "        from meldataset import MAX_WAV_VALUE\n",
    "        from models import Generator\n",
    "\n",
    "        pbar.update(1) # initialized Dependancies\n",
    "\n",
    "        graph_width = 900\n",
    "        graph_height = 360\n",
    "        def plot_data(data, figsize=(int(graph_width/100), int(graph_height/100))):\n",
    "            %matplotlib inline\n",
    "            fig, axes = plt.subplots(1, len(data), figsize=figsize)\n",
    "            for i in range(len(data)):\n",
    "                axes[i].imshow(data[i], aspect='auto', origin='bottom', \n",
    "                            interpolation='none', cmap='inferno')\n",
    "            fig.canvas.draw()\n",
    "            plt.show()\n",
    "\n",
    "        # Setup Pronounciation Dictionary\n",
    "        !gdown --id '1E12g_sREdcH5vuZb44EZYX8JjGWQ9rRp'\n",
    "        thisdict = {}\n",
    "        for line in reversed((open('merged.dict.txt', \"r\").read()).splitlines()):\n",
    "            thisdict[(line.split(\" \",1))[0]] = (line.split(\" \",1))[1].strip()\n",
    "\n",
    "        pbar.update(1) # Downloaded and Set up Pronounciation Dictionary\n",
    "\n",
    "        def ARPA(text, punctuation=r\"!?,.;\", EOS_Token=True):\n",
    "            out = ''\n",
    "            for word_ in text.split(\" \"):\n",
    "                word=word_; end_chars = ''\n",
    "                while any(elem in word for elem in punctuation) and len(word) > 1:\n",
    "                    if word[-1] in punctuation: end_chars = word[-1] + end_chars; word = word[:-1]\n",
    "                    else: break\n",
    "                try:\n",
    "                    word_arpa = thisdict[word.upper()]\n",
    "                    word = \"{\" + str(word_arpa) + \"}\"\n",
    "                except KeyError: pass\n",
    "                out = (out + \" \" + word + end_chars).strip()\n",
    "            if EOS_Token and out[-1] != \";\": out += \";\"\n",
    "            return out\n",
    "\n",
    "        def get_hifigan(MODEL_ID):\n",
    "            # Download HiFi-GAN\n",
    "            hifigan_pretrained_model = 'hifimodel'\n",
    "            gdown.download(d+MODEL_ID, hifigan_pretrained_model, quiet=False)\n",
    "            if not exists(hifigan_pretrained_model):\n",
    "                raise Exception(\"HiFI-GAN model failed to download!\")\n",
    "\n",
    "            # Load HiFi-GAN\n",
    "            conf = os.path.join(\"hifi-gan\", \"config_v1.json\")\n",
    "            with open(conf) as f:\n",
    "                json_config = json.loads(f.read())\n",
    "            h = AttrDict(json_config)\n",
    "            torch.manual_seed(h.seed)\n",
    "            hifigan = Generator(h).to(torch.device(\"cuda\"))\n",
    "            state_dict_g = torch.load(hifigan_pretrained_model, map_location=torch.device(\"cuda\"))\n",
    "            hifigan.load_state_dict(state_dict_g[\"generator\"])\n",
    "            hifigan.eval()\n",
    "            hifigan.remove_weight_norm()\n",
    "            return hifigan, h\n",
    "\n",
    "        hifigan, h = get_hifigan(HIFIGAN_ID)\n",
    "        pbar.update(1) # Downloaded and Set up HiFi-GAN\n",
    "\n",
    "        def has_MMI(STATE_DICT):\n",
    "            return any(True for x in STATE_DICT.keys() if \"mi.\" in x)\n",
    "\n",
    "        def get_Tactron2(MODEL_ID):\n",
    "            # Download Tacotron2\n",
    "            tacotron2_pretrained_model = TACOTRON2_ID\n",
    "            if not exists(tacotron2_pretrained_model):\n",
    "                raise Exception(\"Tacotron2 model failed to download!\")\n",
    "            # Load Tacotron2 and Config\n",
    "            hparams = create_hparams()\n",
    "            hparams.sampling_rate = 22050\n",
    "            hparams.max_decoder_steps = 3000 # Max Duration\n",
    "            hparams.gate_threshold = 0.25 # Model must be 25% sure the clip is over before ending generation\n",
    "            model = Tacotron2(hparams)\n",
    "            state_dict = torch.load(tacotron2_pretrained_model)['state_dict']\n",
    "            if has_MMI(state_dict):\n",
    "                raise Exception(\"ERROR: This notebook does not currently support MMI models.\")\n",
    "            model.load_state_dict(state_dict)\n",
    "            _ = model.cuda().eval().half()\n",
    "            return model, hparams\n",
    "\n",
    "        model, hparams = get_Tactron2(TACOTRON2_ID)\n",
    "        previous_tt2_id = TACOTRON2_ID\n",
    "\n",
    "        pbar.update(1) # Downloaded and Set up Tacotron2\n",
    "\n",
    "        # Extra Info\n",
    "        def end_to_end_infer(text, pronounciation_dictionary, show_graphs):\n",
    "            for i in [x for x in text.split(\"\\n\") if len(x)]:\n",
    "                if not pronounciation_dictionary:\n",
    "                    if i[-1] != \";\": i=i+\";\" \n",
    "                else: i = ARPA(i)\n",
    "                with torch.no_grad(): # save VRAM by not including gradients\n",
    "                    sequence = np.array(text_to_sequence(i, [text_cleaner]))[None, :]\n",
    "                    sequence = torch.autograd.Variable(torch.from_numpy(sequence)).cuda().long()\n",
    "                    mel_outputs, mel_outputs_postnet, _, alignments = model.inference(sequence)\n",
    "                    if show_graphs:\n",
    "                        plot_data((mel_outputs_postnet.float().data.cpu().numpy()[0],\n",
    "                                alignments.float().data.cpu().numpy()[0].T))\n",
    "                    y_g_hat = hifigan(mel_outputs_postnet.float())\n",
    "                    audio = y_g_hat.squeeze()\n",
    "                    audio = audio * MAX_WAV_VALUE\n",
    "                    print(\"\")\n",
    "                    ipd.display(ipd.Audio(audio.cpu().numpy().astype(\"int16\"), rate=hparams.sampling_rate))\n",
    "    from IPython.display import clear_output\n",
    "    clear_output()\n",
    "    initilized = \"Ready\"\n",
    "\n",
    "if previous_tt2_id != TACOTRON2_ID:\n",
    "    print(\"Updating Models\")\n",
    "    model, hparams = get_Tactron2(TACOTRON2_ID)\n",
    "    hifigan, h = get_hifigan(HIFIGAN_ID)\n",
    "    previous_tt2_id = TACOTRON2_ID\n",
    "\n",
    "pronounciation_dictionary = False #@param {type:\"boolean\"}\n",
    "# disables automatic ARPAbet conversion, useful for inputting your own ARPAbet pronounciations or just for testing\n",
    "show_graphs = True #@param {type:\"boolean\"}\n",
    "max_duration = 25 #this does nothing\n",
    "model.decoder.max_decoder_steps = 1000 #@param {type:\"integer\"}\n",
    "stop_threshold = 0.324 #@param {type:\"number\"}\n",
    "model.decoder.gate_threshold = stop_threshold\n",
    "\n",
    "#@markdown ---\n",
    "\n",
    "print(f\"Current Config:\\npronounciation_dictionary: {pronounciation_dictionary}\\nshow_graphs: {show_graphs}\\nmax_duration (in seconds): {max_duration}\\nstop_threshold: {stop_threshold}\\n\\n\")\n",
    "\n",
    "time.sleep(1)\n",
    "print(\"输入要转换成语音的文本.\")\n",
    "contents = []\n",
    "while True:\n",
    "    try:\n",
    "        print(\"-\"*50)\n",
    "        line = input()\n",
    "        if line == \"\":\n",
    "            continue\n",
    "        end_to_end_infer(line, pronounciation_dictionary, show_graphs)\n",
    "    except EOFError:\n",
    "        break\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"程序终止...\")\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
